{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07711ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 23:26:39.288544: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import  LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16fb3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_json('tripadvisor_reviews.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0abecee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(str_list, lemmatize=True):\n",
    "    clean_list = []\n",
    "    \n",
    "    for text in str_list:\n",
    "        # Remove pound sign from hashtags\n",
    "        text = re.sub(r'#', '', text)\n",
    "        words = word_tokenize(text)\n",
    "        clean_words = []\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()  # Move lemmatizer initialization outside the loop\n",
    "        \n",
    "        for word in words:\n",
    "            # Drop words with fewer than 2 characters and drop any punctuation \"words\"\n",
    "            if len(word) > 1 and re.match(r'^\\w+$', word):\n",
    "                if lemmatize:\n",
    "                    word = lemmatizer.lemmatize(word)  # Apply lemmatization\n",
    "                clean_words.append(word)\n",
    "        \n",
    "        clean_text = ' '.join(clean_words)\n",
    "        clean_list.append(clean_text)\n",
    "    \n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d94b5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pikaqiu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/pikaqiu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words_nltk = set(stopwords.words('english'))\n",
    "def remove_stop_words(text):\n",
    "    tokenized_corpus_nltk = word_tokenize(text)\n",
    "    tokenized_corpus_without_stopwords = [i for i in tokenized_corpus_nltk if not i in stop_words_nltk]\n",
    "    return ' '.join(tokenized_corpus_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d137d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['review']= text_df['review'].str.lower()\n",
    "text_df['clean_text']= clean_text(text_df['review'])\n",
    "text_df['clean_text']= text_df['clean_text'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "895a42cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMQP</td>\n",
       "      <td>just returned from a 9 day stay with my family...</td>\n",
       "      <td>returned day stay family le bristol wa perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chelsea Vann</td>\n",
       "      <td>if you're looking for elegance, warmth, beauty...</td>\n",
       "      <td>looking elegance warmth beauty feeling true pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TrailBlazer16673</td>\n",
       "      <td>i have just completed a two-week stay at le br...</td>\n",
       "      <td>completed stay le bristol following unavoidabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raultravel</td>\n",
       "      <td>the bristol hotel is the best hotel and a must...</td>\n",
       "      <td>bristol hotel best hotel sophisticated travele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Villa_Eros_Kefalonia</td>\n",
       "      <td>what can i say but after a nearly two year abs...</td>\n",
       "      <td>say nearly two year absence favourite place ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>KNR25</td>\n",
       "      <td>a big thank you le bristol paris,my daughter w...</td>\n",
       "      <td>big thank le bristol paris daughter remember e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>chantalramard09</td>\n",
       "      <td>very well received, pleasant stay, attentive s...</td>\n",
       "      <td>well received pleasant stay attentive staff pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>Philippe C</td>\n",
       "      <td>wears its status as a parisian palace well. ve...</td>\n",
       "      <td>wear status parisian palace well caring staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>JRM</td>\n",
       "      <td>the bristol paris is a hotel that deserves 6 s...</td>\n",
       "      <td>bristol paris hotel deserves star extraordinar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>roy e</td>\n",
       "      <td>perfection all the way; when you want to treat...</td>\n",
       "      <td>perfection way want treat paradise go setting ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1384 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                                             review  \\\n",
       "0                     RMQP  just returned from a 9 day stay with my family...   \n",
       "1             Chelsea Vann  if you're looking for elegance, warmth, beauty...   \n",
       "2         TrailBlazer16673  i have just completed a two-week stay at le br...   \n",
       "3               Raultravel  the bristol hotel is the best hotel and a must...   \n",
       "4     Villa_Eros_Kefalonia  what can i say but after a nearly two year abs...   \n",
       "...                    ...                                                ...   \n",
       "1379                 KNR25  a big thank you le bristol paris,my daughter w...   \n",
       "1380       chantalramard09  very well received, pleasant stay, attentive s...   \n",
       "1381            Philippe C  wears its status as a parisian palace well. ve...   \n",
       "1382                   JRM  the bristol paris is a hotel that deserves 6 s...   \n",
       "1383                 roy e  perfection all the way; when you want to treat...   \n",
       "\n",
       "                                             clean_text  \n",
       "0     returned day stay family le bristol wa perfect...  \n",
       "1     looking elegance warmth beauty feeling true pa...  \n",
       "2     completed stay le bristol following unavoidabl...  \n",
       "3     bristol hotel best hotel sophisticated travele...  \n",
       "4     say nearly two year absence favourite place ex...  \n",
       "...                                                 ...  \n",
       "1379  big thank le bristol paris daughter remember e...  \n",
       "1380  well received pleasant stay attentive staff pe...  \n",
       "1381  wear status parisian palace well caring staff ...  \n",
       "1382  bristol paris hotel deserves star extraordinar...  \n",
       "1383  perfection way want treat paradise go setting ...  \n",
       "\n",
       "[1384 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a9c542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(text_df.clean_text.values)\n",
    "joined_text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79728313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678882"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7821cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_text = joined_text[:867505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "796fc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbeaa9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token: idx for idx, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b161ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 10\n",
    "input_words = []\n",
    "next_words = []\n",
    "\n",
    "for i in range(len(tokens) - n_words):\n",
    "    input_words.append(tokens[i:i + n_words])\n",
    "    next_words.append(tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a99d0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype = bool)\n",
    "y = np.zeros((len(next_words), len(unique_tokens)), dtype = bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e153dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        X[i, j, unique_token_index[word]] = 1\n",
    "    y[i, unique_token_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6dc9e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences = True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1e78dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "779/779 [==============================] - 249s 313ms/step - loss: 7.2028 - accuracy: 0.0365\n",
      "Epoch 2/10\n",
      "779/779 [==============================] - 232s 298ms/step - loss: 6.9739 - accuracy: 0.0520\n",
      "Epoch 3/10\n",
      "779/779 [==============================] - 233s 298ms/step - loss: 6.7472 - accuracy: 0.0708\n",
      "Epoch 4/10\n",
      "779/779 [==============================] - 236s 303ms/step - loss: 6.5172 - accuracy: 0.0886\n",
      "Epoch 5/10\n",
      "779/779 [==============================] - 236s 302ms/step - loss: 6.3373 - accuracy: 0.1012\n",
      "Epoch 6/10\n",
      "779/779 [==============================] - 237s 304ms/step - loss: 6.1683 - accuracy: 0.1131\n",
      "Epoch 7/10\n",
      "779/779 [==============================] - 239s 307ms/step - loss: 6.0001 - accuracy: 0.1247\n",
      "Epoch 8/10\n",
      "779/779 [==============================] - 239s 307ms/step - loss: 5.8268 - accuracy: 0.1359\n",
      "Epoch 9/10\n",
      "779/779 [==============================] - 249s 319ms/step - loss: 5.6537 - accuracy: 0.1481\n",
      "Epoch 10/10\n",
      "779/779 [==============================] - 259s 332ms/step - loss: 5.4771 - accuracy: 0.1608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fed6ac796d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = RMSprop(learning_rate= 0.01), metrics= [\"accuracy\"])\n",
    "model.fit(X,y, batch_size = 128, epochs = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7473a516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d989fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f44c9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    X = np.zeros((1, n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        X[0, i ,unique_token_index[word]] = 1\n",
    "        \n",
    "    predictions = model.predict(X)[0]\n",
    "    return np.argpartition(predictions, - n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebfd250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "['staff', 'great', 'hotel', 'le', 'one']\n"
     ]
    }
   ],
   "source": [
    "possible = predict_next_word('paris hotel', 5)\n",
    "print([unique_tokens[idx] for idx in possible])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a48288a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text, text_length, creativity= 3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(text_length):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4397c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hotel great great food le le great great food great great'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"hotel\", 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53e662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
